{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "def transcribe(path):\n",
    "  audio_file = open(path, \"rb\")\n",
    "  transcription = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\", \n",
    "    file=audio_file, \n",
    "    response_format=\"text\"\n",
    "  )\n",
    "  return (transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import ShortTermFeatures\n",
    "\n",
    "def audio_analysis(path):\n",
    "    # Load the audio file\n",
    "    audio_path = path\n",
    "    [Fs, x] = audioBasicIO.read_audio_file(audio_path)  # Fs: Sampling rate, x: Audio signal\n",
    "\n",
    "    # Convert to mono if the audio is stereo\n",
    "    if x.ndim > 1:\n",
    "        x = x.mean(axis=1)\n",
    "\n",
    "    # Step size (25ms) and window size (50ms)\n",
    "    step_size = int(0.025 * Fs)  # Convert from seconds to samples\n",
    "    window_size = int(0.05 * Fs)  # Convert from seconds to samples\n",
    "\n",
    "    # Extract short-term features\n",
    "    F, feature_names = ShortTermFeatures.feature_extraction(x, Fs, window_size, step_size)\n",
    "\n",
    "\n",
    "    # Extract specific features for further analysis\n",
    "    energy = F[1]  # Short-term Energy\n",
    "    zcr = F[0]     # Zero-Crossing Rate\n",
    "\n",
    "    # Set a silence threshold based on energy\n",
    "    silence_threshold = 0.05 * np.max(energy)  # 10% of max energy\n",
    "\n",
    "    # Detect pauses (regions where energy is below the threshold)\n",
    "    pauses = np.where(energy < silence_threshold, 1, 0)\n",
    "\n",
    "    # Calculate the total pause duration\n",
    "    total_pause_duration = np.sum(pauses) * (step_size / Fs)\n",
    "\n",
    "    # Calculate average ZCR for voiced regions (where energy > silence threshold)\n",
    "    voiced_regions = energy > silence_threshold\n",
    "    average_zcr = np.mean(zcr[voiced_regions])\n",
    "\n",
    "    # Create a time axis for plotting\n",
    "    time = np.arange(F.shape[1]) * (step_size / Fs)\n",
    "\n",
    "    # Define the ideal range for ZCR\n",
    "    zcr_ideal_min = 0.01\n",
    "    zcr_ideal_max = 0.1\n",
    "\n",
    "    # Score calculation for ZCR\n",
    "    if average_zcr < zcr_ideal_min:\n",
    "        zcr_score = 100  # Perfect score for low ZCR\n",
    "    elif average_zcr > zcr_ideal_max:\n",
    "        zcr_score = 0  # Poor score for high ZCR\n",
    "    else:\n",
    "        zcr_score = 100 * (1 - (average_zcr - zcr_ideal_min) / (zcr_ideal_max - zcr_ideal_min))\n",
    "\n",
    "    total_speech_duration = len(x) / Fs  # Length of audio signal divided by sampling rate\n",
    "\n",
    "    # Define the ideal range for pause percentage\n",
    "    pause_ideal_min = 0  # No pauses\n",
    "    pause_ideal_max = 100  # shit speech\n",
    "    pause_time_percentage = (1 - total_pause_duration / total_speech_duration) * 100\n",
    "\n",
    "    # Score calculation for pause percentage\n",
    "    if pause_time_percentage < pause_ideal_min:\n",
    "        pause_score = 100  # Perfect score for no pauses\n",
    "    elif pause_time_percentage > pause_ideal_max:\n",
    "        pause_score = 0  # Poor score for too many pauses\n",
    "    else:\n",
    "        pause_score = 100 * (1 - (pause_time_percentage - pause_ideal_min) / (pause_ideal_max - pause_ideal_min))\n",
    "\n",
    "    return zcr_score, pause_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"test.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So, the problem wants us to give the index of two elements from the list such that the sum of the numbers at that index is equal to the provided target. Easiest way to do this is the brute force method which is run a loop in a loop to check for the sum is equal to the target. However, this solution is a O of n squared solution, but the question asks us to look for a better solution than O of n square. So, the next approach would be to use a hash map or a dictionary. We store the seen elements as the keys with the index as the values. We continue looping through the list till we find the element whose complement aka the target minus number is in the hash map. When we find such an element, we return the index of the element and its complement. We are using a hash map because the lookup of a hash map function is constant time. The solution has time complexity of O of n making it a better solution.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fluency, avg_pausing = audio_analysis(path)\n",
    "print(avg_fluency, avg_pausing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
